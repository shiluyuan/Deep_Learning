{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import package\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# format data and define parameters\n",
    "train = pd.read_csv(\"mnist_train.csv\")\n",
    "test = pd.read_csv(\"mnist_test.csv\")\n",
    "train = train.sample(frac=1).reset_index(drop=True)\n",
    "# define\n",
    "img_rows, img_cols = 28, 28\n",
    "n_classes = 10\n",
    "batch_size = 128\n",
    "trainning_period = 20\n",
    "learning_rate = 1e-3\n",
    "# format the data\n",
    "train_x = train.iloc[:,1:].as_matrix().reshape(train.shape[0], img_rows, img_cols)\n",
    "train_y_array = train.iloc[:,0]\n",
    "train_y = keras.utils.to_categorical(train_y_array, n_classes)\n",
    "\n",
    "test_x = test.iloc[:,1:].as_matrix().reshape(test.shape[0], img_rows, img_cols)\n",
    "test_y_array = test.iloc[:,0]\n",
    "test_y = keras.utils.to_categorical(test_y_array, n_classes)\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    train_x = train_x.reshape(train_x.shape[0], 1, img_rows, img_cols)\n",
    "    test_x = test_x.reshape(test_x.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    train_x = train_x.reshape(train_x.shape[0], img_rows, img_cols, 1)\n",
    "    test_x = test_x.reshape(test_x.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build network\n",
    "model = Sequential()\n",
    "# add first convolutional layer\n",
    "model.add(Conv2D(32, kernel_size=(5, 5),\n",
    "                 activation='relu',padding='valid',\n",
    "                 input_shape=input_shape))\n",
    "# add maxpooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# add second convolutional layer\n",
    "model.add(Conv2D(64, kernel_size=(5, 5),\n",
    "                 activation='relu',padding='valid',\n",
    "                 input_shape=input_shape))\n",
    "# add maxpooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# add a fully connected layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "# add a dropout rate\n",
    "model.add(Dropout(0.2))\n",
    "# add final layer \n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer = keras.optimizers.Adam(lr=learning_rate,decay=0.01),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 2s - loss: 0.5419 - acc: 0.8360 - val_loss: 0.1672 - val_acc: 0.9465\n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.1467 - acc: 0.9578 - val_loss: 0.1020 - val_acc: 0.9645\n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.1017 - acc: 0.9699 - val_loss: 0.0696 - val_acc: 0.9795\n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.0761 - acc: 0.9772 - val_loss: 0.0557 - val_acc: 0.9835\n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.0617 - acc: 0.9824 - val_loss: 0.0437 - val_acc: 0.9875\n",
      "Epoch 6/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.0513 - acc: 0.9857 - val_loss: 0.0385 - val_acc: 0.9900\n",
      "Epoch 7/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.0475 - acc: 0.9866 - val_loss: 0.0332 - val_acc: 0.9900\n",
      "Epoch 8/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.0387 - acc: 0.9898 - val_loss: 0.0292 - val_acc: 0.9920\n",
      "Epoch 9/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.0358 - acc: 0.9908 - val_loss: 0.0305 - val_acc: 0.9915\n",
      "Epoch 10/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.0326 - acc: 0.9908 - val_loss: 0.0241 - val_acc: 0.9945\n",
      "Epoch 11/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.0280 - acc: 0.9934 - val_loss: 0.0222 - val_acc: 0.9945\n",
      "Epoch 12/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.0261 - acc: 0.9937 - val_loss: 0.0206 - val_acc: 0.9960\n",
      "Epoch 13/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.0231 - acc: 0.9948 - val_loss: 0.0176 - val_acc: 0.9975\n",
      "Epoch 14/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.0221 - acc: 0.9954 - val_loss: 0.0160 - val_acc: 0.9980\n",
      "Epoch 15/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.0217 - acc: 0.9947 - val_loss: 0.0169 - val_acc: 0.9975\n",
      "Epoch 16/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.0198 - acc: 0.9954 - val_loss: 0.0156 - val_acc: 0.9960\n",
      "Epoch 17/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.0179 - acc: 0.9964 - val_loss: 0.0163 - val_acc: 0.9965\n",
      "Epoch 18/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.0173 - acc: 0.9961 - val_loss: 0.0135 - val_acc: 0.9980\n",
      "Epoch 19/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.0160 - acc: 0.9970 - val_loss: 0.0126 - val_acc: 0.9980\n",
      "Epoch 20/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.0139 - acc: 0.9981 - val_loss: 0.0117 - val_acc: 0.9985\n",
      "total time is: 16.206504344940186\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "time_0 = time.time()\n",
    "model.fit(train_x, train_y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=trainning_period,\n",
    "          verbose=1,\n",
    "          validation_data=(test_x, test_y))\n",
    "print(\"total time is:\", time.time() - time_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1344/2000 [===================>..........] - ETA: 0s[[  9.99717057e-01   1.55675339e-09   2.81863875e-04 ...,   3.51404961e-10\n",
      "    1.07107789e-08   1.03072159e-06]\n",
      " [  9.99980092e-01   9.64977473e-11   3.54426993e-06 ...,   1.55820301e-09\n",
      "    7.24995664e-09   1.26439509e-05]\n",
      " [  9.99162555e-01   7.00401017e-08   2.60509289e-04 ...,   3.99985845e-04\n",
      "    1.28167937e-06   1.49774482e-04]\n",
      " ..., \n",
      " [  3.85989990e-10   7.28584727e-13   8.50315790e-11 ...,   4.08214237e-06\n",
      "    2.05817059e-07   9.99993682e-01]\n",
      " [  4.52355486e-10   1.32570702e-14   3.08022829e-10 ...,   2.31452006e-07\n",
      "    3.85992536e-08   9.99999285e-01]\n",
      " [  2.98005023e-11   2.41544011e-08   8.01681499e-11 ...,   4.34523872e-06\n",
      "    1.31381341e-04   9.99797881e-01]]\n",
      "1248/2000 [=================>............] - ETA: 0s[0 0 0 ..., 9 9 9]\n"
     ]
    }
   ],
   "source": [
    "# predict probablity of test data\n",
    "pred_prob = model.predict_proba(test_x)\n",
    "print(pred_prob)\n",
    "# predict class of test data\n",
    "pred_class = model.predict_classes(test_x)\n",
    "print(pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
